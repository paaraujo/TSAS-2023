{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "966e71cc-4090-4e8f-87cf-2b92567c2414",
   "metadata": {},
   "source": [
    "> This notebook implements a LI-EKF and a RI-EKF for GNSS and Odometry integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5b90a1-be3a-401e-a053-71ddfc2bad8c",
   "metadata": {},
   "source": [
    "## Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c84953-7576-4940-a68e-d2feda4f010b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5753/1962359143.py:12: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from collections import OrderedDict\n",
    "from matplotlib import ticker\n",
    "from matplotlib.patches import Rectangle\n",
    "from navpy import lla2ned, ned2lla\n",
    "from tqdm.autonotebook import tqdm\n",
    "from scipy.spatial.transform import Rotation as Rot\n",
    "from scipy.stats import norm\n",
    "from scipy.linalg import inv, expm, logm\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85ba2f3-cae1-47a2-b5c6-1d32e1c9c70e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\"\n",
    "})\n",
    "plt.rcParams['font.size'] = '16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e613aa6b-b679-497d-95f6-1d03dc77c366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LIEKF:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" Initialize the class by creating all the important variable \"\"\"\n",
    "        \n",
    "        ''' Nominal State '''\n",
    "        self.x  = []\n",
    "        \n",
    "        ''' Error State '''\n",
    "        self.dx = []\n",
    "        \n",
    "        ''' Total number of steps processed '''\n",
    "        self.steps = 0\n",
    "\n",
    "        ''' Filter matrices '''\n",
    "        self.P_dim = 15\n",
    "        self.Q_dim = 15\n",
    "        self.X_dim = 15\n",
    "        self.IdP = np.eye(self.P_dim)\n",
    "        self.IdQ = np.eye(self.Q_dim)\n",
    "        self.Id3 = np.eye(3)\n",
    "        self.Id6 = np.eye(6)\n",
    "        self.P = np.eye(self.P_dim)\n",
    "        self.N = np.eye(3)\n",
    "        self.Q = np.eye(self.Q_dim)\n",
    "        \n",
    "        ''' Other '''\n",
    "        self.g = np.array([0.,0.,-9.80665])\n",
    "        \n",
    "        \n",
    "    def initialize(self, x):\n",
    "        \"\"\" Initialize the filter with the nominal state vector \"\"\"\n",
    "        \n",
    "        ''' Initial nominal state '''\n",
    "        p_i_0 = np.array(x[0:3])\n",
    "        v_i_0 = np.array(x[3:6])\n",
    "        \n",
    "        ''' Rotation sequence for Novatel '''\n",
    "        p,r,a = np.array(x[6:9])\n",
    "        R_i_0 = Rot.from_euler('xyz', [p, r, -a], degrees=True)\n",
    "        b_w_0 = np.array(x[9:12])\n",
    "        b_f_0 = np.array(x[12:15])\n",
    "        self.x = [p_i_0, v_i_0, R_i_0, b_w_0, b_f_0]\n",
    "\n",
    "        return None\n",
    "        \n",
    "    def current(self):\n",
    "        \"\"\" Get the current nominal state vector \"\"\"\n",
    "        \n",
    "        p_i, v_i, R_i, b_w, b_f = self.x\n",
    "        \n",
    "        pitch_i, roll_i, yaw_i = R_i.as_euler('xyz', degrees=True)\n",
    "        \n",
    "        # Normalize yaw\n",
    "        factor = 180.    \n",
    "        yaw_i = yaw_i % (2 * factor)    # force in range [0, 2 pi)\n",
    "        if yaw_i > factor:          # move to [-pi, pi)\n",
    "            yaw_i -= 2 * factor\n",
    "        att_i = [pitch_i, roll_i, -yaw_i]\n",
    "        \n",
    "        return p_i, v_i, att_i, b_w, b_f\n",
    "    \n",
    "    \n",
    "    def predict(self, u, dt):\n",
    "        \"\"\" Predict the nominal states using the user inputs \"\"\"\n",
    "        \n",
    "        self.steps += 1\n",
    "        \n",
    "        ''' Previous states '''\n",
    "        p_i_prev, v_i_prev, R_i_prev, b_w_prev, b_f_prev = self.x\n",
    "        \n",
    "        ''' User inputs '''\n",
    "        f_t = u[0:3]\n",
    "        w_t = u[3:6]\n",
    "        \n",
    "        ''' Propagating nominal states '''    \n",
    "        R = R_i_prev.as_matrix() @ expm(self._wedge((w_t-b_w_prev) * dt))\n",
    "        R_i_updt = Rot.from_matrix(R)\n",
    "        acc = R_i_prev.as_matrix().dot(f_t-b_f_prev) + self.g\n",
    "        v_i_updt = v_i_prev + acc * dt\n",
    "        p_i_updt = p_i_prev + v_i_prev * dt + acc * dt**2 * 0.5\n",
    "        b_w_updt = b_w_prev\n",
    "        b_f_updt = b_f_prev\n",
    "        self.x = [p_i_updt, v_i_updt, R_i_updt, b_w_updt, b_f_updt]\n",
    "        \n",
    "        ''' Propagating the covariance '''\n",
    "        A = np.zeros((self.P_dim,self.P_dim))\n",
    "        A[0:3,0:3] = -self._wedge(w_t-b_w_prev)\n",
    "        A[0:3,9:12] = -self.Id3\n",
    "        A[3:6,0:3] = -self._wedge(f_t-b_f_prev)\n",
    "        A[3:6,3:6] = -self._wedge(w_t-b_w_prev)\n",
    "        A[3:6,12:15] = -self.Id3\n",
    "        A[6:9,3:6] = self.Id3\n",
    "        A[6:9,6:9] = -self._wedge(w_t-b_w_prev)\n",
    "        \n",
    "        F = self.IdP + A * dt\n",
    "        G = self.IdQ * dt\n",
    "        self.P = F @ self.P @ F.T + G @ self.Q @ G.T\n",
    "        self.P = 0.5 * np.add(self.P, self.P.T)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def correct(self, y):\n",
    "        \"\"\" Correct the nominal states using the measurements \"\"\"\n",
    "        \n",
    "        ''' Current states '''\n",
    "        p_i_curr, v_i_curr, R_i_curr, b_w_curr, b_f_curr = self.x\n",
    "                \n",
    "        X = self._pack(R_i_curr.as_matrix(), v_i_curr, p_i_curr)\n",
    "        inv_X = inv(X)\n",
    "        N = self.N\n",
    "        \n",
    "        ''' Kalman Gain '''\n",
    "        H = np.zeros((6, self.X_dim))\n",
    "        H[0:6, 3:9] = self.Id6\n",
    "        S = H @ self.P @ H.T + N\n",
    "        K = self.P @ H.T @ inv(S)\n",
    "        \n",
    "        ''' Error state '''\n",
    "        Y = np.array([*y[0:3], 1, 0])\n",
    "        b = np.zeros(5)\n",
    "        b[3] = 1\n",
    "        z_vel = inv_X.dot(Y) - b\n",
    "        \n",
    "        Y = np.array([*y[3:6], 0, 1])\n",
    "        b = np.zeros(5)\n",
    "        b[4] = 1\n",
    "        z_pos = inv_X.dot(Y) - b\n",
    "        \n",
    "        z = np.concatenate((z_vel[0:3],z_pos[0:3]))\n",
    "        e = K.dot(z)\n",
    "        self.dx = e\n",
    "        \n",
    "        ''' Mapping the error '''\n",
    "        Lg = np.zeros((5, 5))\n",
    "        Lg[0:3, 0:3] = self._wedge(e[:3])\n",
    "        Lg[0:3, 3] = e[3:6]\n",
    "        Lg[0:3, 4] = e[6:9]\n",
    "        delta = expm(Lg)\n",
    "        \n",
    "        ''' Correcting states '''\n",
    "        X_updt = X @ delta\n",
    "        R_i_curr = Rot.from_matrix(X_updt[:3,:3])\n",
    "        v_i_curr = np.squeeze(X_updt[:3,3])\n",
    "        p_i_curr = np.squeeze(X_updt[:3,4])\n",
    "        # b_w_curr += e[9:12]\n",
    "        # b_f_curr += e[12:15]\n",
    "        self.x = [p_i_curr, v_i_curr, R_i_curr, b_w_curr, b_f_curr]\n",
    "        \n",
    "        ''' Covariance '''\n",
    "        self.P = (self.IdP - K @ H) @ self.P @ np.transpose(self.IdP - K @ H) + K @ self.N @ K.T\n",
    "        self.P = 0.5 * np.add(self.P, self.P.T)\n",
    "\n",
    "        return None \n",
    "    \n",
    "\n",
    "    def _Adx(self):\n",
    "        p_i_curr, v_i_curr, R_i_curr, b_w_curr, b_f_curr = self.x\n",
    "        Adx = np.zeros((9, 9))\n",
    "        Adx[0:3,0:3] = R_i_curr.as_matrix()\n",
    "        Adx[3:6,0:3] = self._wedge(v_i_curr) @ R_i_curr.as_matrix()\n",
    "        Adx[3:6,3:6] = R_i_curr.as_matrix()\n",
    "        Adx[6:9,0:3] = self._wedge(p_i_curr) @ R_i_curr.as_matrix()\n",
    "        Adx[6:9,6:9] = R_i_curr.as_matrix()\n",
    "        return Adx\n",
    "    \n",
    "    def _Adx_inv(self):\n",
    "        p_i_curr, v_i_curr, R_i_curr, b_w_curr, b_f_curr = self.x\n",
    "        Adx = np.zeros((9, 9))\n",
    "        Adx[0:3,0:3] = R_i_curr.as_matrix().T\n",
    "        Adx[3:6,0:3] = -R_i_curr.as_matrix().T @ self._wedge(v_i_curr)\n",
    "        Adx[3:6,3:6] = R_i_curr.as_matrix().T\n",
    "        Adx[6:9,0:3] = -R_i_curr.as_matrix().T @ self._wedge(p_i_curr)\n",
    "        Adx[6:9,6:9] = R_i_curr.as_matrix().T\n",
    "        return Adx\n",
    "    \n",
    "    \n",
    "    def Pl_to_Pr(self):\n",
    "        Adx = self._Adx()\n",
    "        Σ = np.zeros((self.X_dim,self.X_dim))\n",
    "        Σ[0:9,0:9] = Adx\n",
    "        Σ[9:15,9:15] = self.Id6\n",
    "        return Σ @ self.P @ Σ.T\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _wedge(v):\n",
    "        v0, v1, v2 = v\n",
    "        M = np.array([[0., -v2, v1],\n",
    "                      [v2, 0., -v0],\n",
    "                      [-v1, v0, 0.]])\n",
    "        return M\n",
    "    \n",
    "    @staticmethod\n",
    "    def _vee(M):\n",
    "        v0 = M[2,1]\n",
    "        v1 = M[0,2]\n",
    "        v2 = M[1,0]\n",
    "        return np.array([v0,v1,v2])\n",
    "    \n",
    "    @staticmethod\n",
    "    def _pack(R, v, p):\n",
    "        X = np.eye(5)\n",
    "        X[0:3, 0:3] = R\n",
    "        X[0:3, 3] = v\n",
    "        X[0:3, 4] = p\n",
    "        return X\n",
    "    \n",
    "    @staticmethod\n",
    "    def _unpack(X):\n",
    "        R = X[0:3, 0:3]\n",
    "        p = X[0:3, 3]\n",
    "        v = X[0:3, 4]\n",
    "        return R, v, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5887084d-070c-44cf-a643-af0b4072fbd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Right-Invariant EKF Class for INS/Odometry Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ce58d2-a631-4029-8a0e-d1b56add7ca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RIEKF:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" Initialize the class by creating all the important variable \"\"\"\n",
    "        \n",
    "        ''' Nominal State '''\n",
    "        self.x  = []\n",
    "        \n",
    "        ''' Error State '''\n",
    "        self.dx = []\n",
    "        \n",
    "        ''' Total number of steps processed '''\n",
    "        self.steps = 0\n",
    "\n",
    "        ''' Filter matrices '''\n",
    "        self.P_dim = 15\n",
    "        self.Q_dim = 15\n",
    "        self.X_dim = 15\n",
    "        self.IdP = np.eye(self.P_dim)\n",
    "        self.IdQ = np.eye(self.Q_dim)\n",
    "        self.Id3 = np.eye(3)\n",
    "        self.Id6 = np.eye(6)\n",
    "        self.P = np.eye(self.P_dim)\n",
    "        self.N = np.eye(3)\n",
    "        self.Q = np.eye(self.Q_dim)\n",
    "        \n",
    "        ''' Other '''\n",
    "        self.g = np.array([0.,0.,-9.80665])\n",
    "        \n",
    "        \n",
    "    def initialize(self, x):\n",
    "        \"\"\" Initialize the filter with the nominal state vector \"\"\"\n",
    "        \n",
    "        ''' Initial nominal state '''\n",
    "        p_i_0 = np.array(x[0:3])\n",
    "        v_i_0 = np.array(x[3:6])\n",
    "        \n",
    "        ''' Rotation sequence for Novatel '''\n",
    "        p,r,a = np.array(x[6:9])\n",
    "        R_i_0 = Rot.from_euler('xyz', [p, r, -a], degrees=True)\n",
    "        b_w_0 = np.array(x[9:12])\n",
    "        b_f_0 = np.array(x[12:15])\n",
    "        self.x = [p_i_0, v_i_0, R_i_0, b_w_0, b_f_0]\n",
    "\n",
    "        return None\n",
    "        \n",
    "    def current(self):\n",
    "        \"\"\" Get the current nominal state vector \"\"\"\n",
    "        \n",
    "        p_i, v_i, R_i, b_w, b_f = self.x\n",
    "        \n",
    "        pitch_i, roll_i, yaw_i = R_i.as_euler('xyz', degrees=True)\n",
    "        \n",
    "        # Normalize yaw\n",
    "        factor = 180.    \n",
    "        yaw_i = yaw_i % (2 * factor)    # force in range [0, 2 pi)\n",
    "        if yaw_i > factor:              # move to [-pi, pi)\n",
    "            yaw_i -= 2 * factor\n",
    "        att_i = [pitch_i, roll_i, -yaw_i]\n",
    "        \n",
    "        return p_i, v_i, att_i, b_w, b_f\n",
    "    \n",
    "    \n",
    "    def predict(self, u, dt):\n",
    "        \"\"\" Predict the nominal states using the user inputs \"\"\"\n",
    "        \n",
    "        self.steps += 1\n",
    "        \n",
    "        ''' Previous states '''\n",
    "        p_i_prev, v_i_prev, R_i_prev, b_w_prev, b_f_prev = self.x\n",
    "        \n",
    "        ''' User inputs '''\n",
    "        f_t = u[0:3]\n",
    "        w_t = u[3:6]\n",
    "        \n",
    "        ''' Propagating nominal states '''    \n",
    "        R = R_i_prev.as_matrix() @ expm(self._wedge((w_t-b_w_prev) * dt))\n",
    "        R_i_updt = Rot.from_matrix(R)\n",
    "        acc = R_i_prev.as_matrix().dot(f_t-b_f_prev) + self.g\n",
    "        v_i_updt = v_i_prev + acc * dt\n",
    "        p_i_updt = p_i_prev + v_i_prev * dt + acc * dt**2 * 0.5\n",
    "        b_w_updt = b_w_prev\n",
    "        b_f_updt = b_f_prev\n",
    "        self.x = [p_i_updt, v_i_updt, R_i_updt, b_w_updt, b_f_updt]\n",
    "        \n",
    "        ''' Propagating the covariance '''\n",
    "        A = np.zeros((self.P_dim,self.P_dim))\n",
    "        A[0:3,9:12] = -R_i_prev.as_matrix()\n",
    "        A[3:6,0:3] = self._wedge(self.g)\n",
    "        A[3:6,9:12] = -self._wedge(v_i_prev) @ R_i_prev.as_matrix()\n",
    "        A[3:6,12:15] = -R_i_prev.as_matrix()\n",
    "        A[6:9,3:6] = self.Id3\n",
    "        A[6:9,9:12] = -self._wedge(p_i_prev) @ R_i_prev.as_matrix()\n",
    "                \n",
    "        B = np.zeros((self.P_dim,self.P_dim))\n",
    "        B[0:3,0:3] = R_i_prev.as_matrix()\n",
    "        B[3:6,0:3] = self._wedge(v_i_prev) @ R_i_prev.as_matrix()\n",
    "        B[3:6,3:6] = R_i_prev.as_matrix()\n",
    "        B[6:9,0:3] = self._wedge(p_i_prev) @ R_i_prev.as_matrix()\n",
    "        B[6:9,6:9] = R_i_prev.as_matrix()\n",
    "        B[9:15,9:15] = self.Id6\n",
    "        \n",
    "        F = self.IdP + A * dt\n",
    "        G = B * dt\n",
    "        self.P = F @ self.P @ F.T + G @ self.Q @ G.T\n",
    "        self.P = 0.5 * np.add(self.P, self.P.T)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def correct(self, y):\n",
    "        \"\"\" Correct the nominal states using the measurements \"\"\"\n",
    "        \n",
    "        ''' Current states '''\n",
    "        p_i_curr, v_i_curr, R_i_curr, b_w_curr, b_f_curr = self.x\n",
    "                \n",
    "        X = self._pack(R_i_curr.as_matrix(), v_i_curr, p_i_curr)\n",
    "        inv_X = inv(X)\n",
    "        N = self.N\n",
    "        \n",
    "        ''' Kalman Gain '''\n",
    "        H = np.zeros((3, self.X_dim))\n",
    "        H[0:3, 3:6] = self.Id3\n",
    "        S = H @ self.P @ H.T + N\n",
    "        K = self.P @ H.T @ inv(S)\n",
    "        \n",
    "        ''' Error state '''\n",
    "        Y = np.array([*y[0:3], -1, 0])\n",
    "        b = np.zeros(5)\n",
    "        b[3] = -1\n",
    "        z = X.dot(Y) - b\n",
    "        e = K.dot(z[0:3])\n",
    "        self.dx = e\n",
    "        \n",
    "        ''' Mapping the error '''\n",
    "        Lg = np.zeros((5, 5))\n",
    "        Lg[0:3, 0:3] = self._wedge(e[:3])\n",
    "        Lg[0:3, 3] = e[3:6]\n",
    "        Lg[0:3, 4] = e[6:9]\n",
    "        delta = expm(Lg)\n",
    "        \n",
    "        ''' Correcting states '''\n",
    "        X_updt = delta @ X\n",
    "        R_i_curr = Rot.from_matrix(X_updt[:3,:3])\n",
    "        v_i_curr = np.squeeze(X_updt[:3,3])\n",
    "        p_i_curr = np.squeeze(X_updt[:3,4])\n",
    "        # b_w_curr += e[9:12]\n",
    "        b_f_curr += e[12:15]\n",
    "        self.x = [p_i_curr, v_i_curr, R_i_curr, b_w_curr, b_f_curr]\n",
    "        \n",
    "        ''' Covariance '''\n",
    "        self.P = (self.IdP - K @ H) @ self.P @ np.transpose(self.IdP - K @ H) + K @ self.N @ K.T\n",
    "        self.P = 0.5 * np.add(self.P, self.P.T)\n",
    "\n",
    "        return None \n",
    "    \n",
    "    \n",
    "    def _Adx(self):\n",
    "        p_i_curr, v_i_curr, R_i_curr, b_w_curr, b_f_curr = self.x\n",
    "        Adx = np.zeros((9, 9))\n",
    "        Adx[0:3,0:3] = R_i_curr.as_matrix()\n",
    "        Adx[3:6,0:3] = self._wedge(v_i_curr) @ R_i_curr.as_matrix()\n",
    "        Adx[3:6,3:6] = R_i_curr.as_matrix()\n",
    "        Adx[6:9,0:3] = self._wedge(p_i_curr) @ R_i_curr.as_matrix()\n",
    "        Adx[6:9,6:9] = R_i_curr.as_matrix()\n",
    "        return Adx\n",
    "    \n",
    "\n",
    "    def _Adx_inv(self):\n",
    "        p_i_curr, v_i_curr, R_i_curr, b_w_curr, b_f_curr = self.x\n",
    "        Adx = np.zeros((9, 9))\n",
    "        Adx[0:3,0:3] = R_i_curr.as_matrix().T\n",
    "        Adx[3:6,0:3] = -R_i_curr.as_matrix().T @ self._wedge(v_i_curr)\n",
    "        Adx[3:6,3:6] = R_i_curr.as_matrix().T\n",
    "        Adx[6:9,0:3] = -R_i_curr.as_matrix().T @ self._wedge(p_i_curr)\n",
    "        Adx[6:9,6:9] = R_i_curr.as_matrix().T\n",
    "        return Adx\n",
    "    \n",
    "    \n",
    "    def Pr_to_Pl(self):\n",
    "        Adx = self._Adx_inv()\n",
    "        Ω = np.zeros((self.X_dim,self.X_dim))\n",
    "        Ω[0:9,0:9] = Adx\n",
    "        Ω[9:15,9:15] = self.Id6\n",
    "        return Ω @ self.P @ Ω.T\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _wedge(v):\n",
    "        v0, v1, v2 = v\n",
    "        M = np.array([[0., -v2, v1],\n",
    "                      [v2, 0., -v0],\n",
    "                      [-v1, v0, 0.]])\n",
    "        return M\n",
    "    \n",
    "    @staticmethod\n",
    "    def _vee(M):\n",
    "        v0 = M[2,1]\n",
    "        v1 = M[0,2]\n",
    "        v2 = M[1,0]\n",
    "        return np.array([v0,v1,v2])\n",
    "    \n",
    "    @staticmethod\n",
    "    def _pack(R, v, p):\n",
    "        X = np.eye(5)\n",
    "        X[0:3, 0:3] = R\n",
    "        X[0:3, 3] = v\n",
    "        X[0:3, 4] = p\n",
    "        return X\n",
    "    \n",
    "    @staticmethod\n",
    "    def _unpack(X):\n",
    "        R = X[0:3, 0:3]\n",
    "        p = X[0:3, 3]\n",
    "        v = X[0:3, 4]\n",
    "        return R, v, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d38b6-7346-48e0-8bd2-a7598735d837",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analysis Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744f6051-0d19-4634-9739-00bda52dd76b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Analysis:\n",
    "    \n",
    "    def __init__(self, container):\n",
    "        # Reserved colors\n",
    "        # self.colors = ['magenta','turquoise','k','gold','b']\n",
    "        self.colors = ['magenta','k','turquoise','gold','m','skyblue']\n",
    "        # self.colors = ['#DB162F','#080708','#2D4B73','#D9B70D','#99B4BF','#BF8D30']\n",
    "        \n",
    "        self.methods = [method for method in container.keys() if method not in ['Time','gnss']]\n",
    "        temp = np.array(container['Time']).reshape((-1,1))\n",
    "        columns = ['Time']\n",
    "        for method in self.methods:\n",
    "            temp = np.concatenate([temp,np.array(container[method])], axis=1)\n",
    "            columns += [method+'.east',method+'.north',method+'.up',\n",
    "                        method+'.ve',method+'.vn',method+'.vu',\n",
    "                        method+'.pitch',method+'.roll',method+'.azi']\n",
    "        self.df = pd.DataFrame(temp, columns=columns)\n",
    "        self.init_t = self.df.Time.iat[0]\n",
    "        self.df.loc[:,'Time'] -= self.init_t\n",
    "        self.df.loc[:,'Time'] /= 60.\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def meta(self):\n",
    "        dist = np.sum(np.sqrt(np.sum(np.square(self.df.loc[:,['ref.east','ref.north','ref.up']].to_numpy()[1:,:] - self.df.loc[:,['ref.east','ref.north','ref.up']].to_numpy()[:-1,:]), axis=1)))\n",
    "        print(f'Travelled distance: {dist} m')\n",
    "        print(f'Travelled time: {self.df.Time.iat[-1]} min')\n",
    "        return None\n",
    "    \n",
    "    def export(self, path):\n",
    "        # Exporting poses\n",
    "        for method in self.methods:\n",
    "            all_data = []\n",
    "            p = self.df.loc[:,method+'.pitch'].tolist()\n",
    "            r = self.df.loc[:,method+'.roll'].tolist()\n",
    "            a = self.df.loc[:,method+'.azi'].tolist()\n",
    "            e = self.df.loc[:,method+'.east'].tolist()\n",
    "            n = self.df.loc[:,method+'.north'].tolist()\n",
    "            u = self.df.loc[:,method+'.east'].tolist()\n",
    "            N = len(p)\n",
    "            for i in range(N):\n",
    "                R = Rot.from_euler('xyz', [p[i], r[i], -a[i]], degrees=True)\n",
    "                t = [-e[i], u[i], n[i]]\n",
    "                T = np.eye(4)\n",
    "                T[0:3,0:3] = R.as_matrix()\n",
    "                T[0:3,3] = t\n",
    "                all_data.append(np.ravel(T)[:12])\n",
    "            all_data = np.array(all_data)\n",
    "            np.savetxt(os.path.join(path, method+'.txt'), all_data, fmt='%1.6e')\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def to_kml(self, path, origin):\n",
    "        if cls.initialized:\n",
    "            new_df = self.df.copy(deep=True)\n",
    "            cols_to_keep = ['Time']\n",
    "            for method in self.methods:\n",
    "                cols = [method+'.east',method+'.north',method+'.up']\n",
    "                cols_to_keep += cols\n",
    "                ned = new_df.loc[:,cols].to_numpy()\n",
    "                ned[:, [0, 1]] = ned[:, [1, 0]]\n",
    "                ned[:, 2] *= -1\n",
    "                lat, lon, hgt = ned2lla(ned, *origin)\n",
    "                new_df.loc[:,cols] = np.concatenate([lon.reshape(-1,1), lat.reshape(-1,1), hgt.reshape(-1,1)], axis=1)\n",
    "            new_df = new_df.loc[:, cols_to_keep]\n",
    "            new_df.to_csv(path, index=False)\n",
    "            return None\n",
    "            \n",
    "    \n",
    "    def cdf(self):\n",
    "        print('\\n*** CDF ***\\n')\n",
    "        filtered_methods = [method for method in self.methods if method != 'ref']\n",
    "        fig, ax = plt.subplots(figsize=[6.4, 6.4])\n",
    "        # fig.suptitle('Cumulative Distribution Function')\n",
    "        ax.set_prop_cycle('color', self.colors[2:])\n",
    "        ax.set_xlabel('Error [m]')\n",
    "        ax.set_ylim([0.,1.01])\n",
    "        ax.grid(linestyle=':')\n",
    "        ax.set_xlim(left=0, right=0.01)\n",
    "        max_herr = []\n",
    "        lines = [':',':','-','-']\n",
    "\n",
    "        # Calculating errors\n",
    "        for filtered_method in filtered_methods:\n",
    "            # Position errors\n",
    "            herr = np.sqrt(np.square(self.df.loc[:,'ref.east'].to_numpy() - self.df.loc[:,filtered_method +'.east'].to_numpy()) + \n",
    "                           np.square(self.df.loc[:,'ref.north'].to_numpy() - self.df.loc[:,filtered_method +'.north'].to_numpy()) +\n",
    "                           np.square(self.df.loc[:,'ref.up'].to_numpy() - self.df.loc[:,filtered_method +'.up'].to_numpy()))\n",
    "            herr = np.sort(herr)\n",
    "            print(f'{filtered_method}:\\n\\t ATE: {np.mean(herr)} m \\n\\t MATE: {np.max(herr)} m')\n",
    "            herr_cdf = np.arange(herr.shape[0]) / float(herr.shape[0])\n",
    "            s = lines.pop(0)\n",
    "            ax.plot(herr, herr_cdf, s, label=filtered_method)\n",
    "            max_herr.append(herr[-1])\n",
    "                    \n",
    "        # Finishing plots\n",
    "        ax.yaxis.set_major_formatter(ticker.PercentFormatter(1.0))\n",
    "        ax.set_xlim(left=0,right=min(max_herr))\n",
    "        ax.set_ylim(bottom=0,top=1.01)\n",
    "        ax.legend(fancybox=False)\n",
    "        plt.show()\n",
    "        # plt.close(fig)\n",
    "        return None\n",
    "    \n",
    "        \n",
    "    def states(self, path=''):\n",
    "        t = self.df.loc[:,'Time'].to_numpy()\n",
    "        \n",
    "        # 2D trajectory\n",
    "        # lines = ['-','-','-','-']\n",
    "        lines = ['-','-','-','-']\n",
    "        fig, ax = plt.subplots(figsize=[8.4, 6.8])\n",
    "        \n",
    "        ax.plot(self.df.loc[:,'ref.east'].to_numpy(), self.df.loc[:,'ref.north'].to_numpy(), '--', color=self.colors[1], label='ref')\n",
    "        \n",
    "        ax.set_prop_cycle('color', self.colors[2:])\n",
    "        filtered_methods = [method for method in self.methods if method != 'ref']\n",
    "        \n",
    "        for method in filtered_methods:\n",
    "            s = lines.pop(0)\n",
    "            ax.plot(self.df.loc[:,method +'.east'].to_numpy(), self.df.loc[:,method +'.north'].to_numpy(), s, label=method)\n",
    "            \n",
    "        ax.set_xlim(left=self.df.loc[:,'ref.east'].to_numpy().min()-100,right=self.df.loc[:,'ref.east'].to_numpy().max()+100)\n",
    "        ax.set_ylim(bottom=self.df.loc[:,'ref.north'].to_numpy().min()-100,top=self.df.loc[:,'ref.north'].to_numpy().max()+100)\n",
    "        ax.set_aspect('equal','box')\n",
    "        # ax2.set_aspect('equal','box')\n",
    "        # ax.set_title('2D Trajectory')\n",
    "        ax.set_xlabel('East [m]')\n",
    "        ax.set_ylabel('North [m]')\n",
    "        # ax2.set_xlabel('East [m]')\n",
    "        # ax2.set_ylabel('North [m]')\n",
    "        ax.annotate('start', xy=(self.df.loc[:,'ref.east'].iat[0], self.df.loc[:,'ref.north'].iat[0]), xytext=(self.df.loc[:,'ref.east'].iat[0]+50, self.df.loc[:,'ref.north'].iat[0]+50), xycoords='data',\n",
    "            arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"angle3\"))\n",
    "        ax.annotate('end', xy=(self.df.loc[:,'ref.east'].iat[-1], self.df.loc[:,'ref.north'].iat[-1]), xytext=(self.df.loc[:,'ref.east'].iat[-1]+50, self.df.loc[:,'ref.north'].iat[-1]+50), xycoords='data',\n",
    "            arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"angle3\"))  \n",
    "        ax.legend(fancybox=False)\n",
    "        # ax2.legend(fancybox=False)\n",
    "        ax.grid(linestyle=':')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Figure for attitude angles\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=[10.4, 6.8], sharex=True)\n",
    "\n",
    "        ax1.set_prop_cycle('color', self.colors[1:])\n",
    "        ax2.set_prop_cycle('color', self.colors[1:])\n",
    "        ax3.set_prop_cycle('color', self.colors[1:])\n",
    "\n",
    "        ax1.set_title('pitch')\n",
    "        ax2.set_title('roll')\n",
    "        ax3.set_title('azimuth')\n",
    "\n",
    "        ax1.set_ylabel('[deg]')\n",
    "        ax2.set_ylabel('[deg]')\n",
    "        ax3.set_ylabel('[deg]')\n",
    "\n",
    "        ax1.grid(linestyle=':')\n",
    "        ax2.grid(linestyle=':')\n",
    "        ax3.grid(linestyle=':')\n",
    "\n",
    "        ax1.set_facecolor('white')\n",
    "        ax2.set_facecolor('white')\n",
    "        ax3.set_facecolor('white')\n",
    "\n",
    "        ax3.set_xlabel('Time [min]')\n",
    "\n",
    "        for method in self.methods:\n",
    "            if method == 'ref':\n",
    "                s = '--'\n",
    "            else:\n",
    "                s = '-'\n",
    "            ax1.plot(t, self.df.loc[:,method+'.pitch'].to_numpy(), s)\n",
    "            ax2.plot(t, self.df.loc[:,method+'.roll'].to_numpy(), s)\n",
    "            ax3.plot(t, self.df.loc[:,method+'.azi'].to_numpy(), s)\n",
    "\n",
    "        ax1.legend(self.methods, fancybox=False)\n",
    "        ax2.legend(self.methods, fancybox=False)\n",
    "        ax3.legend(self.methods, fancybox=False)\n",
    "        \n",
    "        ax1.set_xlim([0, np.max(t)])\n",
    "        ax2.set_xlim([0, np.max(t)])\n",
    "        ax3.set_xlim([0, np.max(t)])\n",
    "        plt.show()\n",
    "\n",
    "        # Figure for velocities\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=[10.4, 6.8], sharex=True)\n",
    "\n",
    "        ax1.set_prop_cycle('color', self.colors[1:])\n",
    "        ax2.set_prop_cycle('color', self.colors[1:])\n",
    "        ax3.set_prop_cycle('color', self.colors[1:])\n",
    "\n",
    "        ax1.set_title('ve')\n",
    "        ax2.set_title('vn')\n",
    "        ax3.set_title('vu')\n",
    "\n",
    "        ax1.set_ylabel('[m/s]')\n",
    "        ax2.set_ylabel('[m/s]')\n",
    "        ax3.set_ylabel('[m/s]')\n",
    "\n",
    "        ax1.grid(linestyle=':')\n",
    "        ax2.grid(linestyle=':')\n",
    "        ax3.grid(linestyle=':')\n",
    "\n",
    "        ax1.set_facecolor('white')\n",
    "        ax2.set_facecolor('white')\n",
    "        ax3.set_facecolor('white')\n",
    "        \n",
    "        ax3.set_xlabel('Time [min]')\n",
    "\n",
    "        for method in self.methods:\n",
    "            if method == 'ref':\n",
    "                s = '--'\n",
    "            else:\n",
    "                s = '-'\n",
    "            ax1.plot(t, self.df.loc[:,method+'.ve'].to_numpy(), s)\n",
    "            ax2.plot(t, self.df.loc[:,method+'.vn'].to_numpy(), s)\n",
    "            ax3.plot(t, self.df.loc[:,method+'.vu'].to_numpy(), s)\n",
    "\n",
    "        ax1.set_xlim([0, np.max(t)])\n",
    "        ax2.set_xlim([0, np.max(t)])\n",
    "        ax3.set_xlim([0, np.max(t)])    \n",
    "        \n",
    "        ax1.legend(self.methods, fancybox=False)\n",
    "        ax2.legend(self.methods, fancybox=False)\n",
    "        ax3.legend(self.methods, fancybox=False)\n",
    "        plt.show()\n",
    "        \n",
    "        # plt.close(fig)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def boundaries(self, boundaries):\n",
    "        print('\\n*** BOUNDARIES ***\\n')\n",
    "        \n",
    "        # Horizontal error\n",
    "        herr_list = []\n",
    "        verr_list = []\n",
    "        herr_list.append(boundaries)\n",
    "        verr_list.append(boundaries)\n",
    "        herr_columns = ['HERR']\n",
    "        verr_columns = ['VERR']\n",
    "        filtered_methods = [method for method in self.methods if method != 'ref']\n",
    "\n",
    "        for filtered_method in filtered_methods:\n",
    "            herr_columns.append(filtered_method)\n",
    "            verr_columns.append(filtered_method)\n",
    "            # Position errors\n",
    "            herr = np.sqrt(np.square(self.df.loc[:,'ref.east'].to_numpy() - self.df.loc[:,filtered_method +'.east'].to_numpy()) + \n",
    "                           np.square(self.df.loc[:,'ref.north'].to_numpy() - self.df.loc[:,filtered_method +'.north'].to_numpy()))\n",
    "            verr = np.abs(self.df.loc[:,'ref.up'].to_numpy() - self.df.loc[:,filtered_method +'.up'].to_numpy())\n",
    "\n",
    "            local_herr_list = []\n",
    "            local_verr_list = []\n",
    "            for b in boundaries:\n",
    "                b_herr = (np.sum(herr <= b)/len(herr)) * 100\n",
    "                b_verr = (np.sum(verr <= b) / len(verr)) * 100\n",
    "                local_herr_list.append(b_herr)\n",
    "                local_verr_list.append(b_verr)\n",
    "\n",
    "            herr_list.append(local_herr_list)\n",
    "            verr_list.append(local_verr_list)\n",
    "\n",
    "        herr_df = pd.DataFrame(list(zip(*herr_list)), columns=herr_columns)\n",
    "        verr_df = pd.DataFrame(list(zip(*verr_list)), columns=verr_columns)\n",
    "\n",
    "        print(herr_df)\n",
    "        print()\n",
    "        print(verr_df)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def outages(self, outages):\n",
    "        print('\\n*** OUTAGES ***\\n')\n",
    "        filtered_methods = [method for method in self.methods if method != 'ref']\n",
    "        # Detecting gaps assuming GNSS reading every second\n",
    "        for n, (i, e) in enumerate(outages):\n",
    "            i = (i - self.init_t) / 60\n",
    "            e = (e - self.init_t) / 60\n",
    "            # Indexes to compute absolute errors\n",
    "            idx_abs = self.df.loc[:,'Time'] <= i\n",
    "            # Indexes to compute relative errors\n",
    "            idx_rel = np.bitwise_and(self.df.loc[:,'Time'] > i, self.df.loc[:,'Time'] < e)\n",
    "            # print(np.argwhere(self.df.Time.values > i).tolist(),np.argwhere(self.df.Time.values < e).tolist())\n",
    "            # Distance traveled\n",
    "            gap = self.df.loc[idx_rel,['ref.east','ref.north','ref.up']].to_numpy()\n",
    "            dist = np.sum(np.sqrt(np.sum(np.square(gap[1:,:] - gap[:-1,:]), axis=1)))\n",
    "            # Computing errors for each method\n",
    "            print(f'OUTAGE {n+1} (Init: {i} | End: {e} | Interval: {round((e-i)*60,3)}s | Distance: {round(dist,3)}m)')     \n",
    "            for filtered_method in filtered_methods:\n",
    "                # Absolute position errors\n",
    "                rmse_herr_abs = np.mean(np.sqrt(np.square(self.df.loc[idx_abs,'ref.east'].to_numpy() - self.df.loc[idx_abs,filtered_method +'.east'].to_numpy()) + \n",
    "                               np.square(self.df.loc[idx_abs,'ref.north'].to_numpy() - self.df.loc[idx_abs,filtered_method +'.north'].to_numpy())))\n",
    "                rmse_verr_abs = np.mean(np.abs(self.df.loc[idx_abs,'ref.up'].to_numpy() - self.df.loc[idx_abs,filtered_method +'.up'].to_numpy()))\n",
    "                # Relative position errors\n",
    "                rmse_herr_rel = np.mean(np.sqrt(np.square(self.df.loc[idx_rel,'ref.east'].to_numpy() - self.df.loc[idx_rel,filtered_method +'.east'].to_numpy()) + \n",
    "                               np.square(self.df.loc[idx_rel,'ref.north'].to_numpy() - self.df.loc[idx_rel,filtered_method +'.north'].to_numpy())))\n",
    "                rmse_verr_rel = np.mean(np.abs(self.df.loc[idx_rel,'ref.up'].to_numpy() - self.df.loc[idx_rel,filtered_method +'.up'].to_numpy()))\n",
    "                print(f'{filtered_method}\\n\\t HERR RMSE (abs): {round(rmse_herr_abs,3)}m | VERR RMSE (abs): {round(rmse_verr_abs,3)}m'\n",
    "                                       f'\\n\\t HERR RMSE (rel): {round(abs(rmse_herr_rel-rmse_herr_abs),3)}m | % of Distance: {round(abs(rmse_herr_rel-rmse_herr_abs)/dist*100,3)}'\n",
    "                                       f'\\n\\t VERR RMSE (rel): {round(abs(rmse_verr_rel-rmse_verr_abs),3)}m | % of Distance: {round(abs(rmse_verr_rel-rmse_verr_abs)/dist*100,3)}\\n')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21341d29-6da7-4daf-981c-5ec0c8a20a12",
   "metadata": {},
   "source": [
    "## User Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14f6bd8a-82f0-428a-ad9c-c7ececec2677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_path = '../data/'\n",
    "_, dirs, _ = next(os.walk(search_path), ([],[],[]))\n",
    "trajmulti=widgets.SelectMultiple(\n",
    "    options=sorted(dirs),\n",
    "    description='Trajectories:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e890841a-0607-4282-84be-75e422c739ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f249f676124fee897a6edb4c6cf2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Trajectories:', options=('2022-05-13-10-51-27', '2022-05-16-10-31-07', '2022-05-16…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajmulti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ce214-5111-4ecd-ac0a-b3a4e0c8bc8c",
   "metadata": {},
   "source": [
    "## Evaluating the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dc5a657-26be-4d55-9749-60b2b67e5e84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_early = False\n",
    "total_time = 1.25 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cb5b0e3-0c94-4d07-a185-d032e2dafd4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TRAJECTORY: 2022-09-27-14-46-03 =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c457ef441948bfa07307de6a58151d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26711 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'ref.latitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/venv.3.10.11/lib/python3.10/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/venv.3.10.11/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/venv.3.10.11/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ref.latitude'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 154\u001b[0m\n\u001b[1;32m    149\u001b[0m             imu_ransac\u001b[38;5;241m.\u001b[39mpredict(u\u001b[38;5;241m=\u001b[39mmeas, dt\u001b[38;5;241m=\u001b[39mdt)\n\u001b[1;32m    151\u001b[0m     last_imu_t \u001b[38;5;241m=\u001b[39m t\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mmerged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mref.latitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miat[i] \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39minf:\n\u001b[1;32m    156\u001b[0m     lat \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref.latitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miat[i]\n\u001b[1;32m    157\u001b[0m     lon \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref.longitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miat[i]\n",
      "File \u001b[0;32m~/.pyenv/versions/venv.3.10.11/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/venv.3.10.11/lib/python3.10/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ref.latitude'"
     ]
    }
   ],
   "source": [
    "for trajectory in [search_path + t + '/' for t in trajmulti.value]:\n",
    "    \n",
    "    # Headline\n",
    "    tag = trajectory.split(\"/\")[-2]\n",
    "    print(f'===== TRAJECTORY: {tag} =====')\n",
    "    \n",
    "    # Reading data\n",
    "    ref = pd.read_csv(trajectory + 'inspvax2.csv')\n",
    "    imu = pd.read_csv(trajectory + 'zedFC-zed_front_center-imu-data_raw.csv')  # zedFC-zed_front_center-imu-data_raw\n",
    "    rad = pd.read_csv('../processed/' + tag + '/seq01.csv')\n",
    "    odo = pd.read_csv(trajectory + 'obd-speed.csv')\n",
    "    \n",
    "    # Limiting the data based on the timestamps of the proposed method\n",
    "    ref = ref.loc[(ref.Time.to_numpy()>= rad.Time.iat[0]) & (ref.Time.to_numpy()<= rad.Time.iat[-1]), :]\n",
    "    imu = imu.loc[(imu.Time.to_numpy()>= rad.Time.iat[0]) & (imu.Time.to_numpy()<= rad.Time.iat[-1]), :]\n",
    "    odo = odo.loc[(odo.Time.to_numpy()>= rad.Time.iat[0]) & (odo.Time.to_numpy()<= rad.Time.iat[-1]), :]\n",
    "    \n",
    "    # Adjusting headers\n",
    "    ref.columns = ['Time'] + [\"ref.\"+col for col in ref.columns if col != 'Time']\n",
    "    imu.columns = ['Time'] + [\"imu.\"+col for col in imu.columns if col != 'Time']\n",
    "    rad.columns = ['Time'] + [\"rad.\"+col for col in rad.columns if col != 'Time']\n",
    "    odo.columns = ['Time'] + [\"odo.\"+col for col in odo.columns if col != 'Time']\n",
    "    \n",
    "    # Merging data\n",
    "    merged_df = imu.merge(ref, how='outer', on='Time')\n",
    "    merged_df = merged_df.merge(rad, how='outer', on='Time')\n",
    "    merged_df = merged_df.merge(odo, how='outer', on='Time')\n",
    "    merged_df.fillna(np.inf, inplace=True)\n",
    "    merged_df.sort_values(by=['Time'], inplace=True)\n",
    "    merged_df.reset_index(inplace=True)\n",
    "    \n",
    "    # Time controller\n",
    "    elapsed = 0\n",
    "    \n",
    "    # Auxiliary variables\n",
    "    initialized = False\n",
    "    stopped = False\n",
    "    last_t = None\n",
    "    last_imu_t = None\n",
    "    last_odom_speed = 0.\n",
    "    last_ransac_speed = 0.\n",
    "    last_radar_speed = 0.\n",
    "    outages  = []\n",
    "    container = OrderedDict([('Time',[]),\n",
    "                             ('ref',[]),\n",
    "                             ('imu',[]),\n",
    "                             ('imu-ransac',[]),\n",
    "                             ('imu-odom',[]),\n",
    "                             ('imu-radar',[])\n",
    "                            ])\n",
    "    \n",
    "    # Models\n",
    "    Q = np.diag(np.square([1.6553283669466599e-03, 1.4321879095521371e-03, 1.4882234265217568e-03,\n",
    "                            2.1797426064493874e-02, 1.9199991208121776e-02, 2.4879113136879506e-02,\n",
    "                            0., 0., 0.,\n",
    "                            5.2638535289061445e-06, 3.3703895968698511e-06, 4.6036018107732706e-06,\n",
    "                            8.0578238813921381e-04, 2.9862524546587111e-04, 9.9432771946672657e-04\n",
    "                          ]))\n",
    "    \n",
    "    P = np.square(np.eye(15)*1e-4)\n",
    "    \n",
    "    imu = RIEKF()\n",
    "    imu.Q = Q\n",
    "    imu.P = P\n",
    "    \n",
    "    imu_ransac = RIEKF()\n",
    "    imu_ransac.Q = Q\n",
    "    imu_ransac.P = P\n",
    "    \n",
    "    imu_odom = RIEKF()\n",
    "    imu_odom.Q = Q\n",
    "    imu_odom.P = P\n",
    "    \n",
    "    imu_radar = RIEKF()\n",
    "    imu_radar.Q = Q\n",
    "    imu_radar.P = P\n",
    "    \n",
    "    # Progress bar\n",
    "    pbar = tqdm(total=merged_df.shape[0])\n",
    "    \n",
    "    \n",
    "    # Looping group\n",
    "    for i in range(merged_df.shape[0]):\n",
    "        \n",
    "        # Timestamp\n",
    "        t = merged_df.Time.iat[i]\n",
    "        \n",
    "        # Managing early stop\n",
    "        if stop_early:\n",
    "            if elapsed >= total_time:\n",
    "                break\n",
    "                \n",
    "        # Evaluating sensors               \n",
    "        if merged_df['rad.proposed'].iat[i] != np.inf:\n",
    "            if initialized:\n",
    "                y = np.array([0., merged_df['rad.proposed'].iat[i], 0.])\n",
    "                z = np.abs(merged_df['rad.proposed'].iat[i] - last_radar_speed)\n",
    "                σ = 0.1\n",
    "                β = 1.0\n",
    "                imu_radar.N = np.diag(np.square([1e-1, 1e-1, 1e-1]))\n",
    "                # imu_radar.N = np.diag(np.square([σ * np.power(10., β * np.tanh(z)), σ * np.power(10., β * np.tanh(z)), σ * np.power(10., β * np.tanh(z))]))  # σ * np.power(10., β * np.tanh(z))\n",
    "                imu_radar.correct(y=y)\n",
    "                \n",
    "                # if not np.isnan(merged_df['rad.ransac'].iat[i]):\n",
    "                try:\n",
    "                    y = np.array([0., merged_df['rad.ransac'].iat[i], 0.])\n",
    "                    z = np.abs(merged_df['rad.ransac'].iat[i] - last_ransac_speed)\n",
    "                    imu_ransac.N = np.diag(np.square([1e-1, 1e-1, 1e-1]))\n",
    "                    # imu_ransac.N = np.diag(np.square([σ * np.power(10., β * np.tanh(z)), σ * np.power(10., β * np.tanh(z)), σ * np.power(10., β * np.tanh(z))]))  # σ * np.power(10., β * np.tanh(z))\n",
    "                    imu_ransac.correct(y=y)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "            last_radar_speed = merged_df['rad.proposed'].iat[i]\n",
    "            last_ransac_speed = merged_df['rad.ransac'].iat[i]\n",
    "            \n",
    "        \n",
    "        elif merged_df['odo.speed'].iat[i] != np.inf:\n",
    "            if initialized:\n",
    "                y = np.array([0., merged_df['odo.speed'].iat[i]/3.6, 0.])\n",
    "                z = np.abs(merged_df['odo.speed'].iat[i]/3.6 - last_odom_speed)\n",
    "                σ = 0.1\n",
    "                β = 1.0\n",
    "                imu_odom.N = np.diag(np.square([1e-1, 1e-1, 1e-1]))\n",
    "                # imu_odom.N = np.diag(np.square([σ * np.power(10., β * np.tanh(z)), σ * np.power(10., β * np.tanh(z)), σ * np.power(10., β * np.tanh(z))]))\n",
    "                imu_odom.correct(y=y)\n",
    "        \n",
    "            if merged_df['odo.speed'].iat[i] == 0:\n",
    "                stopped = True\n",
    "            else:\n",
    "                stopped = False        \n",
    "                \n",
    "            last_odom_speed = merged_df['odo.speed'].iat[i]/3.6\n",
    "                \n",
    "        \n",
    "        elif merged_df['imu.linear_acceleration.x'].iat[i] != np.inf:                \n",
    "            if initialized:\n",
    "                meas = [-merged_df['imu.linear_acceleration.y'].iat[i], merged_df['imu.linear_acceleration.x'].iat[i], merged_df['imu.linear_acceleration.z'].iat[i],\n",
    "                        -merged_df['imu.angular_velocity.y'].iat[i], merged_df['imu.angular_velocity.x'].iat[i], merged_df['imu.angular_velocity.z'].iat[i]]\n",
    "                    \n",
    "                dt = t - last_imu_t\n",
    "                elapsed += dt\n",
    "            \n",
    "                # Predicting states\n",
    "                if not stopped:\n",
    "                    imu.predict(u=meas, dt=dt)\n",
    "                    imu_odom.predict(u=meas, dt=dt)\n",
    "                    imu_radar.predict(u=meas, dt=dt)\n",
    "                    imu_ransac.predict(u=meas, dt=dt)\n",
    "                    \n",
    "            last_imu_t = t\n",
    "        \n",
    "        \n",
    "        elif merged_df['ref.latitude'].iat[i] != np.inf:\n",
    "\n",
    "            lat = merged_df['ref.latitude'].iat[i]\n",
    "            lon = merged_df['ref.longitude'].iat[i]\n",
    "            hgt = merged_df['ref.height'].iat[i]\n",
    "            ve = merged_df['ref.east_velocity'].iat[i]\n",
    "            vn = merged_df['ref.north_velocity'].iat[i]\n",
    "            vu = merged_df['ref.up_velocity'].iat[i]\n",
    "            pitch = merged_df['ref.pitch'].iat[i]\n",
    "            roll  = merged_df['ref.roll'].iat[i]\n",
    "            azi   = merged_df['ref.azimuth'].iat[i]\n",
    "            \n",
    "            if not initialized:\n",
    "                origin = [lat, lon, hgt, ve, vn, vu, pitch, roll, azi]\n",
    "                ned = lla2ned(lat, lon, hgt, *origin[:3])\n",
    "                enu = np.array([ned[1],ned[0],-ned[2]])\n",
    "                \n",
    "                imu.initialize([*enu, ve, vn, vu, pitch, roll, azi, *np.zeros(6)])\n",
    "                imu_odom.initialize([*enu, ve, vn, vu, pitch, roll, azi, *np.zeros(6)])\n",
    "                imu_radar.initialize([*enu, ve, vn, vu, pitch, roll, azi, *np.zeros(6)])\n",
    "                imu_ransac.initialize([*enu, ve, vn, vu, pitch, roll, azi, *np.zeros(6)])\n",
    "                initialized = True\n",
    "                \n",
    "            # Storing data\n",
    "            ned = lla2ned(lat, lon, hgt, *origin[:3])\n",
    "            enu = np.array([ned[1],ned[0],-ned[2]])\n",
    "            last_ref = [*enu, ve, vn, vu, pitch, roll, azi]\n",
    "            container['Time'].append(t)\n",
    "            container['ref'].append(last_ref)\n",
    "            p_i, v_i, att_i, _, _ = imu.current()\n",
    "            container['imu'].append([*p_i, *v_i, *att_i])\n",
    "            p_i, v_i, att_i, _, _ = imu_odom.current()\n",
    "            container['imu-odom'].append([*p_i, *v_i, *att_i])\n",
    "            p_i, v_i, att_i, _, _ = imu_radar.current()\n",
    "            container['imu-radar'].append([*p_i, *v_i, *att_i])\n",
    "            p_i, v_i, att_i, _, _ = imu_ransac.current()\n",
    "            container['imu-ransac'].append([*p_i, *v_i, *att_i])\n",
    "               \n",
    "        \n",
    "        last_t = t\n",
    "        pbar.update(n=1)\n",
    "        \n",
    "    # Analysis for current trajectory\n",
    "    analysis = Analysis(container)\n",
    "    analysis.meta()\n",
    "    analysis.cdf()\n",
    "    analysis.export('../output/')\n",
    "    # analysis.cdf()\n",
    "    # analysis.errors()\n",
    "    analysis.states()\n",
    "    # analysis.boundaries([0.5,1.0,2.0,5.0,10.0,25.0,50.0])\n",
    "    # analysis.outages(outages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c846f098-30e1-4023-9bf9-e01138447ee2",
   "metadata": {
    "tags": []
   },
   "source": [
    "z = np.linspace(0, 5, 200)\n",
    "β = 0.1\n",
    "σ = 0.1\n",
    "y = σ * np.power(10., β * np.tanh(z))\n",
    "\n",
    "plt.plot(z,y**2)\n",
    "y**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99f9b8-1122-45ac-89cd-2b8b0b2c1c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
